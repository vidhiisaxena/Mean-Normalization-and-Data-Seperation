{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOqwmUZXMXW1aXvrnHWaci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidhiisaxena/Mean-Normalization-and-Data-Seperation/blob/main/Mean_Normalization_and_Data_Seperation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Normalization\n",
        "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is normalized in order to work correctly. The idea of normalization, also known as feature scaling, is to ensure that all the data is on a similar scale, i.e. that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1."
      ],
      "metadata": {
        "id": "zZHyQP5_bxPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import NumPy into Python\n",
        "import numpy as np\n",
        "\n",
        "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
        "X = np.random.randint(0,5001,size=(1000, 20))\n",
        "\n",
        "# print the shape of X\n",
        "print(\"Shape of X is: \", X.shape)"
      ],
      "metadata": {
        "id": "TaR-j1Lvb8FF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7b05a0-77af-4e44-c074-7b6c9f863fdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X is:  (1000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average of the values in each column of X\n",
        "ave_cols =np.mean(X, axis=0)\n",
        "\n",
        "# Standard Deviation of the values in each column of X\n",
        "std_cols = np.std(X, axis=0)"
      ],
      "metadata": {
        "id": "t6oas0adJeNV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of ave_cols\n",
        "print(ave_cols.shape)\n",
        "\n",
        "# Print the shape of std_cols\n",
        "print(std_cols.shape)"
      ],
      "metadata": {
        "id": "kYJeUypqb8Mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66066b0d-a061-44ef-faf0-539f1fe18745"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20,)\n",
            "(20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will perform mean normalization using the following equation:**\n",
        "\n",
        "*Norm_Colùëñ = ( Colùëñ - Average ) / Stardard Deviation*"
      ],
      "metadata": {
        "id": "M61ts588KOBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean normalize X\n",
        "X_norm = (X-ave_cols)/std_cols"
      ],
      "metadata": {
        "id": "zHbNgD38J0KE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the average of all the values of X_norm\n",
        "print(\"The average of all the values of X_norm is: \")\n",
        "print(X_norm.mean())\n",
        "\n",
        "# Print the average of the minimum value in each column of X_norm\n",
        "print(\"The average of minimum values in each column of X_norm is: \")\n",
        "print(X_norm.max(axis = 0).mean())\n",
        "\n",
        "# Print the average of the maximum value in each column of X_norm\n",
        "print(\"The average of maximum values in each column of X_norm is: \")\n",
        "print(X_norm.min(axis=0).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnr_WBB8J0WP",
        "outputId": "aa66998d-2193-47ea-fe36-ba34f93b2728"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average of all the values of X_norm is: \n",
            "-1.3322676295501878e-17\n",
            "The average of minimum values in each column of X_norm is: \n",
            "1.7378590284024242\n",
            "The average of maximum values in each column of X_norm is: \n",
            "-1.7332469756282962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Separation\n",
        "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
        "\n",
        "A Training Set\n",
        "\n",
        "*   A Training Set\n",
        "*   A Cross Validation Set\n",
        "*   A Test Set\n",
        "\n",
        "\n",
        "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data.\n",
        "\n",
        "Separating X_norm into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of X_norm chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of X_norm are chosen and randomly distributed among the three new sets."
      ],
      "metadata": {
        "id": "C8vI6peHLhXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a random permutation of integers 0 to 4\n",
        "np.random.permutation(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3YrktrzJ0e5",
        "outputId": "9743c367-1051-4895-a57a-32a5cfa833a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 4, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
        "row_indices = np.random.permutation(X_norm.shape[0])"
      ],
      "metadata": {
        "id": "ahfLiQ1TM9l3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the count of 60% rows. Since, len(X_norm) has a lenght 1000, therefore, 60% = 600\n",
        "sixty = int(len(X_norm) * 0.6)\n",
        "\n",
        "# Let's get the count of 80% rows\n",
        "eighty = int(len(X_norm) * 0.8)\n",
        "\n",
        "# Create a Training Set\n",
        "# Here row_indices[:sixty] will give you first 600 values, e.g., [93 255 976 505 281 292 977,.....]\n",
        "# Those 600 values will will be random, because row_indices is a 1-D array of random integers.\n",
        "# Next, extract all rows represented by these 600 indices, as X_norm[row_indices[:sixty], :]\n",
        "X_train = X_norm[row_indices[:sixty], :]\n",
        "\n",
        "# Create a Cross Validation Set\n",
        "X_crossVal = X_norm[row_indices[sixty: eighty], :]\n",
        "\n",
        "# Create a Test Set\n",
        "X_test = X_norm[row_indices[eighty: ], :]"
      ],
      "metadata": {
        "id": "utPONWa6M9zA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of X_train\n",
        "print(X_train.shape)\n",
        "\n",
        "# Print the shape of X_crossVal\n",
        "print(X_crossVal.shape)\n",
        "\n",
        "# Print the shape of X_test\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXPDPrAmNSR5",
        "outputId": "6b857c4b-bad5-46f3-ec95-092f8f1b4019"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 20)\n",
            "(200, 20)\n",
            "(200, 20)\n"
          ]
        }
      ]
    }
  ]
}